<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE TS>
<TS version="2.1" language="en_US" sourcelanguage="zh_CN">
<context>
    <name></name>
    <message>
        <source>选择模型文件所在的文件夹</source>
        <translation type="vanished">Select the folder where the model file is located</translation>
    </message>
    <message>
        <source>选择缓存文件夹</source>
        <translation type="vanished">Select cache folder</translation>
    </message>
    <message>
        <source>选择音频文件</source>
        <translation type="vanished">Select Target File</translation>
    </message>
    <message>
        <source>模型未加载！进程退出</source>
        <translation type="vanished">The model has not been loaded</translation>
    </message>
    <message>
        <source>存在无效文件：</source>
        <translation type="vanished">Invalid file exists:</translation>
    </message>
    <message>
        <source>  开始  </source>
        <translation type="obsolete">  Start  </translation>
    </message>
    <message>
        <source>退出</source>
        <translation type="vanished">Quit</translation>
    </message>
    <message>
        <source>是否要退出程序？</source>
        <translation type="vanished">DoYou want to Quit？</translation>
    </message>
</context>
<context>
    <name>FileNameListView</name>
    <message>
        <location filename="faster_whisper_GUI/fileNameListViewInterface.py" line="53"/>
        <source>存在无效文件：</source>
        <translation>Invalid file :</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/fileNameListViewInterface.py" line="64"/>
        <location filename="faster_whisper_GUI/fileNameListViewInterface.py" line="81"/>
        <source>剔除文件</source>
        <translation>Ignore Files</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/fileNameListViewInterface.py" line="64"/>
        <source>存在无效文件，已剔除
</source>
        <translation>Invalid file , ignored
</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/fileNameListViewInterface.py" line="81"/>
        <source>已知的字幕格式文件已忽略
</source>
        <translation>ignored subtitle files
</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/fileNameListViewInterface.py" line="92"/>
        <source>选择音频文件</source>
        <translation>Select Target File</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/fileNameListViewInterface.py" line="119"/>
        <source>忽略已存在的文件</source>
        <translation>ignored files in list</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/fileNameListViewInterface.py" line="119"/>
        <source>重复添加的文件将被忽略：
</source>
        <translation>Repeatedly added files are ignored:
</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/fileNameListViewInterface.py" line="150"/>
        <source>音视频文件列表</source>
        <translation>Audio-Video Files List</translation>
    </message>
</context>
<context>
    <name>MainWindows</name>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="130"/>
        <source>选择缓存文件夹</source>
        <translation>Select cache folder</translation>
    </message>
    <message>
        <source>选择音频文件</source>
        <translation type="vanished">Select Target File</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="172"/>
        <source>需要模型所在目录或者有效的模型名称。</source>
        <translation>Model-dir or Model-name is needed.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="178"/>
        <source>加载本地模型</source>
        <translation>Load local model</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="181"/>
        <source>在线下载模型</source>
        <translation>Download Model Online</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="209"/>
        <source>加载模型</source>
        <translation>Load Model</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="209"/>
        <source>模型加载中，请稍候</source>
        <translation>Please wait a moment while the model is loading</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="288"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="362"/>
        <source>模型未加载！进程退出</source>
        <translation>The model has not been loaded</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="304"/>
        <source>  取消  </source>
        <translation>  Cancel  </translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="363"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="372"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="665"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="718"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="781"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="796"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="819"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="863"/>
        <source>错误</source>
        <translation>Error</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="363"/>
        <source>模型未加载！</source>
        <translation>The model has not been loaded!</translation>
    </message>
    <message>
        <source>存在无效文件：</source>
        <translation type="vanished">Invalid file exists:</translation>
    </message>
    <message>
        <source>    取消</source>
        <translation type="vanished">    Cancel</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="395"/>
        <source>音频处理</source>
        <translation>Audio process</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="395"/>
        <source>正在处理中</source>
        <translation>on processing</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="391"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="400"/>
        <source>取消</source>
        <translation>Cancel</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="171"/>
        <source>模型名称错误</source>
        <translation>Model Name Error</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="373"/>
        <source>没有选择有效的音视频文件作为转写对象</source>
        <translation>No valid audio and video file is selected</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="401"/>
        <source>是否取消操作？</source>
        <translation>Do you want to cancel pocess?</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="407"/>
        <source>已取消</source>
        <translation>Canceled</translation>
    </message>
    <message>
        <source>    开始</source>
        <translation type="vanished">    Process</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="411"/>
        <source>开始</source>
        <translation>Start</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="500"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="715"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="743"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="779"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="861"/>
        <source>结束</source>
        <translation>Over</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="508"/>
        <source>成功</source>
        <translation>Succeed</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="509"/>
        <source>转写完成</source>
        <translation>Over</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="662"/>
        <source>Model Convert only Work In Onlie-Mode</source>
        <translation>Model Convert only Work In Onlie-Mode</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="666"/>
        <source>转换功能仅在在线模式下工作</source>
        <translation>Convert function only work in online-mode</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="676"/>
        <source>Convert Model: </source>
        <translation>Convert Model: </translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="708"/>
        <source>加载完成</source>
        <translation>Load Over</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="710"/>
        <source>加载结束</source>
        <translation>Load Over</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="712"/>
        <source>模型加载成功</source>
        <translation>Model load successful</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="719"/>
        <source>加载失败，退出并检查 fasterWhispergui.log 文件可能会获取错误信息。</source>
        <translation>Failed to load Model, exit and check for file &quot;fasterwhispergui.log&quot; may get error information.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="734"/>
        <source>选择模型文件所在的文件夹</source>
        <translation>Select the folder where the model file is located</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="743"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="761"/>
        <source>保存文件</source>
        <translation>Save to files</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="746"/>
        <source>保存完成</source>
        <translation>Saved</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="747"/>
        <source>字幕文件已保存</source>
        <translation>Subtitle Files saved</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="761"/>
        <source>输出字幕文件</source>
        <translation>Output to files</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="779"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="788"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="804"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="850"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="861"/>
        <location filename="faster_whisper_GUI/mainWindows.py" line="870"/>
        <source>WhisperX</source>
        <translation>WhisperX</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="781"/>
        <source>对齐失败，退出软件后检查 fasterwhispergui.log 文件可能会获取错误信息</source>
        <translation>Alignment failed. Checking the fasterwhispergui.log file after exiting the software may get error messages</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="789"/>
        <source>时间戳对齐结束</source>
        <translation>Over</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="798"/>
        <source>没有有效的 音频-字幕 转写结果，无法进行对齐</source>
        <translation>No valid audio-subtitle transliteration result, unable to align</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="804"/>
        <source>时间戳对齐</source>
        <translation>Timestamp alignment</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="821"/>
        <source>没有有效的 音频-字幕 转写结果，无法输出人声分离结果</source>
        <translation>No valid audio-subtitle transliteration result, unable to output human voice separation result</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="850"/>
        <source>声源分离</source>
        <translation>Speaker diarize</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="863"/>
        <source>声源分离失败，退出软件后检查 fasterwhispergui.log 文件可能会获取错误信息</source>
        <translation>Sound source separation failed. Checking the fasterwhispergui.log file after exiting the software may get error messages</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="871"/>
        <source>声源分离结束</source>
        <translation>Over</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="929"/>
        <source>退出</source>
        <translation>Quit</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/mainWindows.py" line="929"/>
        <source>是否要退出程序？</source>
        <translation>DoYou want to Quit？</translation>
    </message>
</context>
<context>
    <name>ModelNavigationInterface</name>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="29"/>
        <source>Model</source>
        <translation>Model</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="30"/>
        <source>加载本地模型或下载模型</source>
        <translation>Load local model or Download Model</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="63"/>
        <source>使用本地模型</source>
        <translation>Local Model</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="64"/>
        <source>本地模型需使用经过 CTranslate2 转换工具，从 OpenAI 模型格式转换而来的模型</source>
        <translation>This mode need a local model that had been converted to CTranslate2 format</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="73"/>
        <source>模型目录</source>
        <translation>Model Path</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="87"/>
        <source>在线下载模型</source>
        <translation>Download Model Online</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="88"/>
        <source>下载可能会花费很长时间，具体取决于网络状态，
作为参考 large-v2 模型下载量最大约 6GB</source>
        <translation>download model from https://huggingface.co/models ，
you can also access this and download model by yourself</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="97"/>
        <source>模型名称</source>
        <translation>Model Name</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="120"/>
        <source>处理设备：</source>
        <translation>Device:</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="131"/>
        <source>设备号：</source>
        <translation>device_index:</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="134"/>
        <source>要使用的设备ID。也可以通过传递ID列表(例如0,1,2,3)在多GPU上加载模型。</source>
        <translation>ID of device that you want to use,
it support multi-value, just like: 0,1,2 .</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="142"/>
        <source>计算精度：</source>
        <translation>compute_type:</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="149"/>
        <source>要使用的计算精度，尽管某些设备不支持半精度，
但事实上不论选择什么精度类型都可以隐式转换。
请参阅 https://opennmt.net/CTranslate2/quantization.html。</source>
        <translation>Type to use for computation.
See https://opennmt.net/CTranslate2/quantization.html.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="155"/>
        <source>线程数（CPU）</source>
        <translation>cpu_threads ( CPU )</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="158"/>
        <source>在CPU上运行时使用的线程数(默认为4)。非零值会覆盖</source>
        <translation>Number of threads to use when running on CPU (4 by default).
A non zero value overrides the OMP_NUM_THREADS environment variable</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="164"/>
        <source>并发数</source>
        <translation>num_workers</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="167"/>
        <source>具有多个工作线程可以在运行模型时实现真正的并行性。
这可以以增加内存使用为代价提高整体吞吐量。</source>
        <translation>When transcribe() is called from multiple Python threads,
having multiple workers enables true parallelism when running the model
This can improve the global throughput at the cost of increased memory usage.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="173"/>
        <source>下载缓存目录</source>
        <translation>download_root</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="176"/>
        <source>模型下载保存的目录。如果未修改,
则模型将保存在标准Hugging Face缓存目录中。</source>
        <translation>Directory where the models should be saved. If not set, the models
are saved in the standard Hugging Face cache directory.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="184"/>
        <source>是否使用本地缓存</source>
        <translation>local_files_only</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="188"/>
        <source>如果为True，在本地缓存的文件存在时返回其路径，不再重新下载文件。</source>
        <translation>If True, avoid downloading the file and return the path to the local cached file if it exists.
It&apos;s a force item for load model,but a Optional item for convert model.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="197"/>
        <source>模型输出目录</source>
        <translation>Convert Model to</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="201"/>
        <source>转换模型的保存目录，不会自动创建子目录</source>
        <translation>Convert model to this path</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="205"/>
        <source>下载并转换模型</source>
        <translation>Download And Convert Model</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="206"/>
        <source>转换 OpenAi 模型到本地格式，
必须选择在线模型</source>
        <translation>Convert OpenAI whisper model to faster-whisper model format</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/modelPageNavigationInterface.py" line="210"/>
        <source>加载模型</source>
        <translation>Load Model</translation>
    </message>
</context>
<context>
    <name>NavigationBaseInterface</name>
    <message>
        <location filename="faster_whisper_GUI/navigationInterface.py" line="183"/>
        <source>模型已加载!</source>
        <translation>Model Loaded!</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/navigationInterface.py" line="186"/>
        <source>模型未加载!</source>
        <translation>Model Not Loaded!</translation>
    </message>
</context>
<context>
    <name>OutputPageNavigationInterface</name>
    <message>
        <location filename="faster_whisper_GUI/outputPageNavigationInterface.py" line="38"/>
        <source>WhisperX And Output</source>
        <translation>WhisperX And Output</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/outputPageNavigationInterface.py" line="38"/>
        <source>whisperX后处理及字幕文件输出</source>
        <translation>WhisperX post-processing and subtitle file output</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/outputPageNavigationInterface.py" line="47"/>
        <source>输出文件目录</source>
        <translation>Output to</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/outputPageNavigationInterface.py" line="51"/>
        <source>输出文件保存的目录</source>
        <translation>Subtitles will output to this dir</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/outputPageNavigationInterface.py" line="52"/>
        <source>当目录为空的时候将会自动输出到每一个音频文件所在目录</source>
        <translation>When the directory is empty, it will be automatically output to the directory where each audio file is located</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/outputPageNavigationInterface.py" line="58"/>
        <source>选择输出目录</source>
        <translation>Select output dir</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/outputPageNavigationInterface.py" line="66"/>
        <source>WhisperX 时间戳对齐</source>
        <translation>WhisperX engine Timestamp alignment</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/outputPageNavigationInterface.py" line="67"/>
        <source>wav2vec2 模型进行音素分析，并进行字幕时间戳对齐，该功能需要有对应的语言的模型支持。</source>
        <translation>The wav2vec2 model carries on the phoneme analysis and the subtitle timestamp alignment, which needs to be supported by the corresponding language model.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/outputPageNavigationInterface.py" line="70"/>
        <source>WhisperX 说话人分离</source>
        <translation>WhisperX engine Speaker Diarize</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/outputPageNavigationInterface.py" line="71"/>
        <source>speachBrain 模型声纹聚类分析，将不同语音段的不同说话人进行分离</source>
        <translation>SpeachBrain model voiceprint cluster analysis to separate different speakers in different speech segments</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/outputPageNavigationInterface.py" line="79"/>
        <source>保存字幕文件</source>
        <translation>Save To Files</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/outputPageNavigationInterface.py" line="80"/>
        <source>保存结果到字幕文件</source>
        <translation>Save result to files</translation>
    </message>
</context>
<context>
    <name>ProcessPageNavigationInterface</name>
    <message>
        <location filename="faster_whisper_GUI/processPageNavigationInterface.py" line="41"/>
        <source>Transcription</source>
        <translation>Transcription</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/processPageNavigationInterface.py" line="42"/>
        <source>选择文件、字幕文件保存目录、转写文件</source>
        <translation>select target files、subtitle file path、process files</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/processPageNavigationInterface.py" line="53"/>
        <source>转写文件</source>
        <translation>Transcribe Files</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/processPageNavigationInterface.py" line="58"/>
        <source>音频采集</source>
        <translation>Audio Capture</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/processPageNavigationInterface.py" line="64"/>
        <source>音频采集参数</source>
        <translation>Audio Capture</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/processPageNavigationInterface.py" line="86"/>
        <source>开始</source>
        <translation>Start</translation>
    </message>
    <message>
        <source>目标音频文件</source>
        <translation type="vanished">Target Files</translation>
    </message>
    <message>
        <source>要转写的音频文件路径</source>
        <translation type="vanished">Target File</translation>
    </message>
    <message>
        <source>选择要转写的音频文件</source>
        <translation type="vanished">Target File</translation>
    </message>
    <message>
        <source>输出文件目录</source>
        <translation type="vanished">Output to</translation>
    </message>
    <message>
        <source>输出文件保存的目录</source>
        <translation type="vanished">Subtitles will output to this dir</translation>
    </message>
    <message>
        <source>选择输出目录</source>
        <translation type="vanished">Select output dir</translation>
    </message>
    <message>
        <source>      开始</source>
        <translation type="vanished">      Process</translation>
    </message>
</context>
<context>
    <name>TabInterface</name>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="87"/>
        <source>标签移动</source>
        <translation>isTabScrollAble</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="88"/>
        <source>标签滚动</source>
        <translation>isTabMoveable</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="89"/>
        <source>标签阴影</source>
        <translation>isTabShadowEnble</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="90"/>
        <source>最大宽度</source>
        <translation>TabMaxWidth</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="92"/>
        <source>关闭按钮显示模式</source>
        <translation>TabCloseButtonDisplayMode</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="95"/>
        <source>最少声源数</source>
        <translation>min speaker</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="97"/>
        <source>音频中需分出来的最少的说话人的人数</source>
        <translation>min-num speakers to diarize</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="99"/>
        <source>最大声源数</source>
        <translation>mac speaker</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="101"/>
        <source>音频中需分出来的最多的说话人的人数</source>
        <translation>max-num speakers to diarize</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="103"/>
        <source>表格样式控制</source>
        <translation>TabStyleControl</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="104"/>
        <source>whisperX 参数控制</source>
        <translation>whisperX control</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="124"/>
        <source>始终显示</source>
        <translation>Always</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="125"/>
        <source>进入时显示</source>
        <translation>onHover</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tableViewInterface.py" line="126"/>
        <source>从不显示</source>
        <translation>Nerver</translation>
    </message>
</context>
<context>
    <name>ToolBar</name>
    <message>
        <location filename="faster_whisper_GUI/navigationInterface.py" line="72"/>
        <source>软件更新</source>
        <translation>Update</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/navigationInterface.py" line="80"/>
        <source>模型状态：</source>
        <translation>Model Status:</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/navigationInterface.py" line="120"/>
        <source>切换主题</source>
        <translation>Change Theme</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/navigationInterface.py" line="122"/>
        <location filename="faster_whisper_GUI/navigationInterface.py" line="129"/>
        <source>关于</source>
        <translation>About</translation>
    </message>
</context>
<context>
    <name>TranscribeNavigationInterface</name>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="28"/>
        <source>FasterWhisper</source>
        <translation>FasterWhisper</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="29"/>
        <source>faster-whisper 模型全部参数</source>
        <translation>faster-whisper paraments</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="51"/>
        <source>输出文件格式</source>
        <translation>Output Format</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="55"/>
        <source>输出字幕文件的格式</source>
        <translation>format of output subtitles</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="61"/>
        <source>语言</source>
        <translation>Language</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="73"/>
        <source>音频中的语言。如果选择 Auto，则自动在音频的前30秒内检测语言。</source>
        <translation>The language spoken in the audio.If set &quot;Auto&quot;,
 the language will be detected in the first 30 seconds of audio.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="78"/>
        <source>翻译为英语</source>
        <translation>Translate</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="84"/>
        <source>输出转写结果翻译为英语的翻译结果</source>
        <translation>Translate result to English</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="88"/>
        <source>分块大小</source>
        <translation>beam_size</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="93"/>
        <source>用于解码的音频块的大小。</source>
        <translation>Beam size to use for decoding.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="97"/>
        <source>最佳热度</source>
        <translation>best_of</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="100"/>
        <source>采样时使用非零热度的候选数</source>
        <translation>Number of candidates when sampling with non-zero temperature</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="104"/>
        <source>搜索耐心</source>
        <translation>patience</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="108"/>
        <source>搜索音频块时的耐心因子</source>
        <translation>Beam search patience factor</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="113"/>
        <source>惩罚常数</source>
        <translation>length_penalty</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="118"/>
        <source>指数形式的长度惩罚常数</source>
        <translation>Exponential length penalty constant</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="122"/>
        <source>采样热度候选</source>
        <translation>temperature</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="125"/>
        <source>采样的温度。
当程序因为压缩比参数或者采样标记概率参数失败时会依次使用</source>
        <translation>Temperature for sampling. It can be a tuple of temperatures,
            which will be successively used upon failures according to either
            `compression_ratio_threshold` or `log_prob_threshold`</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="129"/>
        <source>温度回退提示重置</source>
        <translation>prompt reset on temperature</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="132"/>
        <source>如果运行中热度回退配置生效，则配置温度回退步骤后，应重置带有先前文本的提示</source>
        <translation>to configure after which temperature fallback step the prompt with the previous text should be reset (default value is 0.5)</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="136"/>
        <source>gzip 压缩比阈值</source>
        <translation>compression_ratio_threshold</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="141"/>
        <source>如果音频的gzip压缩比高于此值，则视为失败。</source>
        <translation>If the gzip compression ratio is above this value, treat as failed.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="145"/>
        <source>采样概率阈值</source>
        <translation>log_prob_threshold</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="150"/>
        <source>如果采样标记的平均对数概率阈值低于此值，则视为失败</source>
        <translation>If the average log probability over sampled tokens is below this value, treat as failed</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="154"/>
        <source>静音阈值</source>
        <translation>no_speech_threshold</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="159"/>
        <source>音频段的如果非语音概率高于此值，
并且对采样标记的平均对数概率低于阈值，
则将该段视为静音。</source>
        <translation>If the no_speech probability is higher than this value AND
the average log probability over sampled tokens is below `log_prob_threshold`,
consider the segment as silent.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="163"/>
        <source>循环提示</source>
        <translation>condition_on_previous_text</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="169"/>
        <source>如果启用，则将模型的前一个输出作为下一个音频段的提示;
禁用可能会导致文本在段与段之间不一致，
但模型不太容易陷入失败循环，
比如重复循环或时间戳失去同步。</source>
        <translation>If True, the previous output of the model is provided
as a prompt for the next window; disabling may make the text inconsistent across
windows, but the model becomes less prone to getting stuck in a failure loop,
such as repetition looping or timestamps going out of sync.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="173"/>
        <source>重复惩罚</source>
        <translation>repetition penalty</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="178"/>
        <source>对先前输出进行惩罚的分数（防重复），设置值&gt;1以进行惩罚</source>
        <translation>to penalize the score of previously generated tokens (set &gt; 1 to penalize)</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="182"/>
        <source>禁止重复的ngram大小</source>
        <translation>no_repeat_ngram_size</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="187"/>
        <source>如果重复惩罚配置生效，该参数防止程序重复使用此大小进行 n-gram 匹配</source>
        <translation>to prevent repetitions of n-grams with this size</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="191"/>
        <source>初始提示词</source>
        <translation>initial_prompt</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="193"/>
        <source>为第一个音频段提供的可选文本字符串或词元 id 提示词，可迭代项。</source>
        <translation>Optional text string or iterable of token ids to provide as a prompt for the first window.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="197"/>
        <source>初始文本前缀</source>
        <translation>prefix</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="199"/>
        <source>为初始音频段提供的可选文本前缀。</source>
        <translation>Optional text to provide as a prefix for the first window.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="203"/>
        <source>空白抑制</source>
        <translation>suppress_blank</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="207"/>
        <source>在采样开始时抑制空白输出。</source>
        <translation>Suppress blank outputs at the beginning of the sampling.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="211"/>
        <source>特定标记抑制</source>
        <translation>suppress_tokens</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="214"/>
        <source>要抑制的标记ID列表。 
-1 将抑制模型配置文件 config.json 中定义的默认符号集。</source>
        <translation>List of token IDs to suppress. -1 will suppress a default set
of symbols as defined in the model config.json file.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="218"/>
        <source>关闭时间戳细分</source>
        <translation>without_timestamps</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="224"/>
        <source>开启时将会输出长文本段落并对应长段落时间戳，不再进行段落细分以及相应的时间戳输出</source>
        <translation>When turned on, a long text paragraph will be output and will correspond to a long paragraph timestamp</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="228"/>
        <source>最晚初始时间戳</source>
        <translation>max_initial_timestamp</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="231"/>
        <source>首个时间戳不能晚于此时间。</source>
        <translation>The initial timestamp cannot be later than this.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="235"/>
        <source>单词级时间戳</source>
        <translation>word_timestamps</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="242"/>
        <source>输出卡拉OK式歌词，支持 SMI VTT LRC 格式</source>
        <translation>output karaoka lyrics, only work in SMI VTT LRC format</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="246"/>
        <source>标点向后合并</source>
        <translation>prepend_punctuations</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="249"/>
        <source>如果开启单词级时间戳，
则将这些标点符号与下一个单词合并。</source>
        <translation>If word_timestamps is True, merge these punctuation symbols with the next word.</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="253"/>
        <source>标点向前合并</source>
        <translation>append_punctuations</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/tranccribePageNavigationInterface.py" line="256"/>
        <source>如果开启单词级时间戳，
则将这些标点符号与前一个单词合并。</source>
        <translation>If word_timestamps is True, merge these punctuation symbols with the previous word.</translation>
    </message>
</context>
<context>
    <name>UIMainWin</name>
    <message>
        <location filename="faster_whisper_GUI/UI_MainWindows.py" line="184"/>
        <source>模型参数</source>
        <translation>Model Option</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/UI_MainWindows.py" line="188"/>
        <source>VAD及WhisperX</source>
        <translation>VAD And WhisperX</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/UI_MainWindows.py" line="192"/>
        <source>转写参数</source>
        <translation>Transcribe Option</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/UI_MainWindows.py" line="196"/>
        <source>执行转写</source>
        <translation>Process</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/UI_MainWindows.py" line="200"/>
        <source>后处理及输出</source>
        <translation>Post-processing and output</translation>
    </message>
    <message>
        <source>选择模型文件所在的文件夹</source>
        <translation type="vanished">Select the folder where the model file is located</translation>
    </message>
</context>
<context>
    <name>VADNavigationInterface</name>
    <message>
        <location filename="faster_whisper_GUI/vadPageNavigationInterface.py" line="26"/>
        <source>Silero VAD</source>
        <translation>Silero VAD</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/vadPageNavigationInterface.py" line="27"/>
        <source>VAD（人声活动检测）及 VAD 模型参数</source>
        <translation>VAD（Vocal Active Detect）And VAD Paraments</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/vadPageNavigationInterface.py" line="43"/>
        <source>是否启用 VAD 及 VAD 参数</source>
        <translation>VAD Use</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/vadPageNavigationInterface.py" line="45"/>
        <source>VAD 模型常用来对语音文件的空白段进行筛除, 可以有效减小 Whisper 模型幻听</source>
        <translation>Use VAD Model to preprocess data or not</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/vadPageNavigationInterface.py" line="56"/>
        <source>阈值</source>
        <translation>threshold</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/vadPageNavigationInterface.py" line="64"/>
        <source>最小语音持续时间(ms)</source>
        <translation>min_speech_duration (ms)</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/vadPageNavigationInterface.py" line="72"/>
        <source>最大语音块时长(s)</source>
        <translation>max_speech_duration (s)</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/vadPageNavigationInterface.py" line="81"/>
        <source>最小静息时长(ms)</source>
        <translation>min_silence_duration (ms)</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/vadPageNavigationInterface.py" line="92"/>
        <source>采样窗口大小</source>
        <translation>window_size_samples</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/vadPageNavigationInterface.py" line="97"/>
        <source>指定大小的音频块被馈送到silero VAD模型。
警告!
Silero VAD模型使用16000采样率训练得到512,1024,1536样本。
其他值可能会影响模型性能!</source>
        <translation>Audio chunks of window_size_samples size are fed to the silero VAD model.
WARNING! Silero VAD models were trained using 512, 1024, 1536 samples for 16000 sample rate.
Values other than these may affect model performance!!</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/vadPageNavigationInterface.py" line="102"/>
        <source>语音块前后填充</source>
        <translation>speech_pad (ms)</translation>
    </message>
    <message>
        <source>WhisperX 时间戳对齐</source>
        <translation type="vanished">WhisperX engine Timestamp alignment</translation>
    </message>
    <message>
        <source>启用 whisperX 引擎进行字幕时间戳对齐，该功能将会自动生成单词级时间戳
根据您选择的输出语言，启用该功能意味着首次运行该功能可能需要联网下载相应模型</source>
        <translation type="vanished">Timestamp alignment using the whisperx engine</translation>
    </message>
    <message>
        <source>WhisperX 说话人分离</source>
        <translation type="vanished">WhisperX engine Speaker Diarize</translation>
    </message>
    <message>
        <source>启用 whisperX 引擎进行声源分离标注
该功能需要提供HuggingFace令牌</source>
        <translation type="vanished">Enable whisperX engine for sound source separation labeling</translation>
    </message>
    <message>
        <location filename="faster_whisper_GUI/vadPageNavigationInterface.py" line="137"/>
        <source>HuggingFace用户令牌</source>
        <oldsource>用户令牌</oldsource>
        <translation>Hugging Face User Token</translation>
    </message>
    <message>
        <source>最少声源数</source>
        <translation type="vanished">min speaker</translation>
    </message>
    <message>
        <source>音频中需分出来的最少的说话人的人数</source>
        <translation type="vanished">min-num speakers to diarize</translation>
    </message>
    <message>
        <source>最大声源数</source>
        <translation type="vanished">mac speaker</translation>
    </message>
    <message>
        <source>音频中需分出来的最多的说话人的人数</source>
        <translation type="vanished">max-num speakers to diarize</translation>
    </message>
</context>
<context>
    <name>mainWin</name>
    <message>
        <source>模型参数</source>
        <translation type="vanished">Model Option</translation>
    </message>
    <message>
        <source>VAD 参数</source>
        <translation type="vanished">VAD Option</translation>
    </message>
    <message>
        <source>VAD及WhisperX</source>
        <translation type="obsolete">VAD And WhisperX</translation>
    </message>
    <message>
        <source>转写参数</source>
        <translation type="vanished">Transcribe Option</translation>
    </message>
    <message>
        <source>执行转写</source>
        <translation type="vanished">Process</translation>
    </message>
    <message>
        <source>转写文件</source>
        <translation type="vanished">Transcribe Files</translation>
    </message>
    <message>
        <source>音频采集</source>
        <translation type="vanished">Audio Capture</translation>
    </message>
    <message>
        <source>音频采集参数</source>
        <translation type="vanished">Audio Capture</translation>
    </message>
    <message>
        <source>目标音频文件</source>
        <translation type="vanished">Target Files</translation>
    </message>
    <message>
        <source>要转写的音频文件路径</source>
        <translation type="vanished">Target File</translation>
    </message>
    <message>
        <source>选择要转写的音频文件</source>
        <translation type="vanished">Target File</translation>
    </message>
    <message>
        <source>输出文件目录</source>
        <translation type="vanished">Output to</translation>
    </message>
    <message>
        <source>输出文件保存的目录</source>
        <translation type="vanished">Subtitles will output to this dir</translation>
    </message>
    <message>
        <source>选择输出目录</source>
        <translation type="vanished">Select output dir</translation>
    </message>
    <message>
        <source>  开始  </source>
        <translation type="vanished">  Start  </translation>
    </message>
    <message>
        <source>输出文件格式</source>
        <translation type="vanished">Output Format</translation>
    </message>
    <message>
        <source>输出字幕文件的格式</source>
        <translation type="vanished">format of output subtitles</translation>
    </message>
    <message>
        <source>语言</source>
        <translation type="vanished">Language</translation>
    </message>
    <message>
        <source>音频中的语言。如果选择 Auto，则自动在音频的前30秒内检测语言。</source>
        <translation type="vanished">The language spoken in the audio.If set &quot;Auto&quot;,
 the language will be detected in the first 30 seconds of audio.</translation>
    </message>
    <message>
        <source>翻译为英语</source>
        <translation type="vanished">Translate</translation>
    </message>
    <message>
        <source>输出转写结果翻译为英语的翻译结果</source>
        <translation type="vanished">Translate result to English</translation>
    </message>
    <message>
        <source>分块大小</source>
        <translation type="vanished">beam_size</translation>
    </message>
    <message>
        <source>用于解码的音频块的大小。</source>
        <translation type="vanished">Beam size to use for decoding.</translation>
    </message>
    <message>
        <source>最佳热度</source>
        <translation type="vanished">best_of</translation>
    </message>
    <message>
        <source>采样时使用非零热度的候选数</source>
        <translation type="vanished">Number of candidates when sampling with non-zero temperature</translation>
    </message>
    <message>
        <source>搜索耐心</source>
        <translation type="vanished">patience</translation>
    </message>
    <message>
        <source>搜索音频块时的耐心因子</source>
        <translation type="vanished">Beam search patience factor</translation>
    </message>
    <message>
        <source>惩罚常数</source>
        <translation type="vanished">length_penalty</translation>
    </message>
    <message>
        <source>指数形式的长度惩罚常数</source>
        <translation type="vanished">Exponential length penalty constant</translation>
    </message>
    <message>
        <source>采样热度候选</source>
        <translation type="vanished">temperature</translation>
    </message>
    <message>
        <source>采样的温度。
当程序因为压缩比参数或者采样标记概率参数失败时会依次使用</source>
        <translation type="vanished">Temperature for sampling. It can be a tuple of temperatures,
            which will be successively used upon failures according to either
            `compression_ratio_threshold` or `log_prob_threshold`</translation>
    </message>
    <message>
        <source>温度回退提示重置</source>
        <translation type="vanished">prompt reset on temperature</translation>
    </message>
    <message>
        <source>如果运行中热度回退配置生效，则配置温度回退步骤后，应重置带有先前文本的提示</source>
        <translation type="vanished">to configure after which temperature fallback step the prompt with the previous text should be reset (default value is 0.5)</translation>
    </message>
    <message>
        <source>gzip 压缩比阈值</source>
        <translation type="vanished">compression_ratio_threshold</translation>
    </message>
    <message>
        <source>如果音频的gzip压缩比高于此值，则视为失败。</source>
        <translation type="vanished">If the gzip compression ratio is above this value, treat as failed.</translation>
    </message>
    <message>
        <source>采样概率阈值</source>
        <translation type="vanished">log_prob_threshold</translation>
    </message>
    <message>
        <source>如果采样标记的平均对数概率阈值低于此值，则视为失败</source>
        <translation type="vanished">If the average log probability over sampled tokens is below this value, treat as failed</translation>
    </message>
    <message>
        <source>静音阈值</source>
        <translation type="vanished">no_speech_threshold</translation>
    </message>
    <message>
        <source>音频段的如果非语音概率高于此值，
并且对采样标记的平均对数概率低于阈值，
则将该段视为静音。</source>
        <translation type="vanished">If the no_speech probability is higher than this value AND
the average log probability over sampled tokens is below `log_prob_threshold`,
consider the segment as silent.</translation>
    </message>
    <message>
        <source>循环提示</source>
        <translation type="vanished">condition_on_previous_text</translation>
    </message>
    <message>
        <source>如果启用，则将模型的前一个输出作为下一个音频段的提示;
禁用可能会导致文本在段与段之间不一致，
但模型不太容易陷入失败循环，
比如重复循环或时间戳失去同步。</source>
        <translation type="vanished">If True, the previous output of the model is provided
as a prompt for the next window; disabling may make the text inconsistent across
windows, but the model becomes less prone to getting stuck in a failure loop,
such as repetition looping or timestamps going out of sync.</translation>
    </message>
    <message>
        <source>重复惩罚</source>
        <translation type="vanished">repetition penalty</translation>
    </message>
    <message>
        <source>对先前输出进行惩罚的分数（防重复），设置值&gt;1以进行惩罚</source>
        <translation type="vanished">to penalize the score of previously generated tokens (set &gt; 1 to penalize)</translation>
    </message>
    <message>
        <source>禁止重复的ngram大小</source>
        <translation type="vanished">no_repeat_ngram_size</translation>
    </message>
    <message>
        <source>如果重复惩罚配置生效，该参数防止程序重复使用此大小进行 n-gram 匹配</source>
        <translation type="vanished">to prevent repetitions of n-grams with this size</translation>
    </message>
    <message>
        <source>初始提示词</source>
        <translation type="vanished">initial_prompt</translation>
    </message>
    <message>
        <source>为第一个音频段提供的可选文本字符串或词元 id 提示词，可迭代项。</source>
        <translation type="vanished">Optional text string or iterable of token ids to provide as a prompt for the first window.</translation>
    </message>
    <message>
        <source>初始文本前缀</source>
        <translation type="vanished">prefix</translation>
    </message>
    <message>
        <source>为初始音频段提供的可选文本前缀。</source>
        <translation type="vanished">Optional text to provide as a prefix for the first window.</translation>
    </message>
    <message>
        <source>关闭时间戳细分</source>
        <translation type="vanished">without_timestamps</translation>
    </message>
    <message>
        <source>开启时将会输出长文本段落并对应长段落时间戳，不再进行段落细分以及相应的时间戳输出</source>
        <translation type="vanished">When turned on, a long text paragraph will be output and will correspond to a long paragraph timestamp</translation>
    </message>
    <message>
        <source>VAD 模型常用来对语音文件的空白段进行筛除, 可以有效减小 Whisper 模型幻听</source>
        <translation type="vanished">Use VAD Model to preprocess data or not</translation>
    </message>
    <message>
        <source>WhisperX 时间戳对齐</source>
        <translation type="vanished">WhisperX engine Timestamp alignment</translation>
    </message>
    <message>
        <source>启用 whisperX 引擎进行字幕时间戳对齐，该功能将会自动生成单词级时间戳
根据您选择的输出语言，启用该功能意味着首次运行该功能可能需要联网下载相应模型</source>
        <translation type="vanished">Timestamp alignment using the whisperx engine</translation>
    </message>
    <message>
        <source>WhisperX 说话人分离</source>
        <translation type="vanished">WhisperX engine Speaker Diarize</translation>
    </message>
    <message>
        <source>启用 whisperX 引擎进行声源分离标注
该功能需要提供HuggingFace令牌</source>
        <translation type="vanished">Enable whisperX engine for sound source separation labeling</translation>
    </message>
    <message>
        <source>用户令牌</source>
        <translation type="vanished">Hugging Face User Token</translation>
    </message>
    <message>
        <source>访问声源分析、分离模型需要提供经过许可的 HuggingFace 用户令牌
如果默认令牌失效可以尝试自行注册账号并生成、刷新令牌</source>
        <translation type="vanished">A licensed HuggingFace user token is required to access the sound source analysis and separation model.
If the default token is invalid, you can try to register your account and generate and refresh the token</translation>
    </message>
    <message>
        <source>最少声源数</source>
        <translation type="vanished">min speaker</translation>
    </message>
    <message>
        <source>最大声源数</source>
        <translation type="vanished">mac speaker</translation>
    </message>
    <message>
        <source>为第初始音频段提供的可选文本前缀。</source>
        <translation type="vanished">Optional text to provide as a prefix for the first window.</translation>
    </message>
    <message>
        <source>空白抑制</source>
        <translation type="vanished">suppress_blank</translation>
    </message>
    <message>
        <source>在采样开始时抑制空白输出。</source>
        <translation type="vanished">Suppress blank outputs at the beginning of the sampling.</translation>
    </message>
    <message>
        <source>特定标记抑制</source>
        <translation type="vanished">suppress_tokens</translation>
    </message>
    <message>
        <source>要抑制的标记ID列表。 
-1 将抑制模型配置文件 config.json 中定义的默认符号集。</source>
        <translation type="vanished">List of token IDs to suppress. -1 will suppress a default set
of symbols as defined in the model config.json file.</translation>
    </message>
    <message>
        <source>关闭时间戳</source>
        <translation type="vanished">without_timestamps</translation>
    </message>
    <message>
        <source>开启时将会仅输出文本不输出时间戳</source>
        <translation type="vanished">Only sample text tokens</translation>
    </message>
    <message>
        <source>最晚初始时间戳</source>
        <translation type="vanished">max_initial_timestamp</translation>
    </message>
    <message>
        <source>首个时间戳不能晚于此时间。</source>
        <translation type="vanished">The initial timestamp cannot be later than this.</translation>
    </message>
    <message>
        <source>单词级时间戳</source>
        <translation type="vanished">word_timestamps</translation>
    </message>
    <message>
        <source>输出卡拉OK式歌词，支持 SMI VTT LRC 格式</source>
        <translation type="vanished">output karaoka lyrics, only work in SMI VTT LRC format</translation>
    </message>
    <message>
        <source>标点向后合并</source>
        <translation type="vanished">prepend_punctuations</translation>
    </message>
    <message>
        <source>如果开启单词级时间戳，
则将这些标点符号与下一个单词合并。</source>
        <translation type="vanished">If word_timestamps is True, merge these punctuation symbols with the next word.</translation>
    </message>
    <message>
        <source>标点向前合并</source>
        <translation type="vanished">append_punctuations</translation>
    </message>
    <message>
        <source>如果开启单词级时间戳，
则将这些标点符号与前一个单词合并。</source>
        <translation type="vanished">If word_timestamps is True, merge these punctuation symbols with the previous word.</translation>
    </message>
    <message>
        <source>使用本地模型</source>
        <translation type="vanished">Local Model</translation>
    </message>
    <message>
        <source>本地模型需使用经过 CTranslate2 转换工具，从 OpenAI 模型格式转换而来的模型</source>
        <translation type="vanished">This mode need a local model that had been converted to CTranslate2 format</translation>
    </message>
    <message>
        <source>模型文件路径</source>
        <translation type="vanished">Model files path</translation>
    </message>
    <message>
        <source>在线下载模型</source>
        <translation type="vanished">Download Model Online</translation>
    </message>
    <message>
        <source>下载可能会花费很长时间，具体取决于网络状态，
作为参考 large-v2 模型下载量最大约 6GB</source>
        <translation type="vanished">download model from https://huggingface.co/models ，
you can also access this and download model by yourself</translation>
    </message>
    <message>
        <source>模型名称</source>
        <translation type="vanished">Model Name</translation>
    </message>
    <message>
        <source>处理设备：</source>
        <translation type="vanished">Device:</translation>
    </message>
    <message>
        <source>设备号：</source>
        <translation type="vanished">device_index:</translation>
    </message>
    <message>
        <source>要使用的设备ID。也可以通过传递ID列表(例如0,1,2,3)在多GPU上加载模型。</source>
        <translation type="vanished">ID of device that you want to use,
it support multi-value, just like: 0,1,2 .</translation>
    </message>
    <message>
        <source>计算精度：</source>
        <translation type="vanished">compute_type:</translation>
    </message>
    <message>
        <source>要使用的计算精度，尽管某些设备不支持半精度，
但事实上不论选择什么精度类型都可以隐式转换。
请参阅 https://opennmt.net/CTranslate2/quantization.html。</source>
        <translation type="vanished">Type to use for computation.
See https://opennmt.net/CTranslate2/quantization.html.</translation>
    </message>
    <message>
        <source>线程数（CPU）</source>
        <translation type="vanished">cpu_threads ( CPU )</translation>
    </message>
    <message>
        <source>在CPU上运行时使用的线程数(默认为4)。非零值会覆盖</source>
        <translation type="vanished">Number of threads to use when running on CPU (4 by default).
A non zero value overrides the OMP_NUM_THREADS environment variable</translation>
    </message>
    <message>
        <source>并发数</source>
        <translation type="vanished">num_workers</translation>
    </message>
    <message>
        <source>具有多个工作线程可以在运行模型时实现真正的并行性。
这可以以增加内存使用为代价提高整体吞吐量。</source>
        <translation type="vanished">When transcribe() is called from multiple Python threads,
having multiple workers enables true parallelism when running the model
This can improve the global throughput at the cost of increased memory usage.</translation>
    </message>
    <message>
        <source>下载缓存目录</source>
        <translation type="vanished">download_root</translation>
    </message>
    <message>
        <source>模型下载保存的目录。如果未修改,
则模型将保存在标准Hugging Face缓存目录中。</source>
        <translation type="vanished">Directory where the models should be saved. If not set, the models
are saved in the standard Hugging Face cache directory.</translation>
    </message>
    <message>
        <source>是否使用本地缓存</source>
        <translation type="vanished">local_files_only</translation>
    </message>
    <message>
        <source>如果为True，在本地缓存的文件存在时返回其路径，不再重新下载文件。</source>
        <translation type="vanished">If True, avoid downloading the file and return the path to the local cached file if it exists.
It&apos;s a force item for load model,but a Optional item for convert model.</translation>
    </message>
    <message>
        <source>模型输出目录</source>
        <translation type="vanished">Convert Model to</translation>
    </message>
    <message>
        <source>转换模型的保存目录，不会自动创建子目录</source>
        <translation type="vanished">Convert model to this path</translation>
    </message>
    <message>
        <source>转换模型</source>
        <translation type="vanished">Convert Model</translation>
    </message>
    <message>
        <source>转换 OpenAi 模型到本地格式，
必须选择在线模型</source>
        <translation type="vanished">Convert OpenAI whisper model to faster-whisper model format</translation>
    </message>
    <message>
        <source>加载模型</source>
        <translation type="vanished">Load Model</translation>
    </message>
    <message>
        <source>是否启用 VAD 及 VAD 参数</source>
        <translation type="vanished">VAD Use</translation>
    </message>
    <message>
        <source>VAD 模型常用来对语音文件的空白段进行筛除, 可以有效减小 Whsiper 模型幻听</source>
        <translation type="vanished">Use VAD Model to preprocess data or not</translation>
    </message>
    <message>
        <source>阈值</source>
        <translation type="vanished">threshold</translation>
    </message>
    <message>
        <source>语音阈值。
 Silero VAD为每个音频块输出语音概率,概率高于此值的认为是语音。
最好对每个数据集单独调整此参数,
但“懒散”的0.5对大多数数据集来说都非常好。</source>
        <translation type="vanished">Speech threshold. Silero VAD outputs speech probabilities for each audio chunk,
probabilities ABOVE this value are considered as SPEECH. It is better to tune this
parameter for each dataset separately, but &quot;lazy&quot; 0.5 is pretty good for most datasets.</translation>
    </message>
    <message>
        <source>最小语音持续时间(ms)</source>
        <translation type="vanished">min_speech_duration (ms)</translation>
    </message>
    <message>
        <source>短于该参数值的最终语音块会被抛弃。</source>
        <translation type="vanished">Final speech chunks shorter min_speech_duration_ms are thrown out.
max_speech_duration_s: Maximum duration of speech chunks in seconds. Chunks longer
than max_speech_duration_s will be split at the timestamp of the last silence that
lasts more than 100ms (if any), to prevent aggressive cutting. Otherwise, they will be
split aggressively just before max_speech_duration_s.</translation>
    </message>
    <message>
        <source>最大语音块时长(s)</source>
        <translation type="vanished">max_speech_duration (s)</translation>
    </message>
    <message>
        <source>语音块的最大持续时间(秒)。
比该参数值指定时长更长的块将在最后一个持续时间超过100ms的静音时间戳拆分(如果有的话),
以防止过度切割。
否则,它们将在参数指定值的时长之前强制拆分。</source>
        <translation type="vanished">Maximum duration of speech chunks in seconds. Chunks longer
than max_speech_duration_s will be split at the timestamp of the last silence that
lasts more than 100ms (if any), to prevent aggressive cutting. Otherwise, they will be
split aggressively just before max_speech_duration_s.</translation>
    </message>
    <message>
        <source>最小静息时长(ms)</source>
        <translation type="vanished">min_silence_duration (ms)</translation>
    </message>
    <message>
        <source>在每个语音块结束时等待该参数值指定的时长再拆分它。</source>
        <translation type="vanished">In the end of each speech chunk wait for min_silence_duration_ms before separating it.</translation>
    </message>
    <message>
        <source>采样窗口大小</source>
        <translation type="vanished">window_size_samples</translation>
    </message>
    <message>
        <source>指定大小的音频块被馈送到silero VAD模型。
警告!
Silero VAD模型使用16000采样率训练得到512,1024,1536样本。
其他值可能会影响模型性能!</source>
        <translation type="vanished">Audio chunks of window_size_samples size are fed to the silero VAD model.
WARNING! Silero VAD models were trained using 512, 1024, 1536 samples for 16000 sample rate.
Values other than these may affect model performance!!</translation>
    </message>
    <message>
        <source>语音块前后填充</source>
        <translation type="vanished">speech_pad (ms)</translation>
    </message>
    <message>
        <source>最终的语音块前后都由指定时长的空白填充。</source>
        <translation type="vanished">Final speech chunks are padded by speech_pad_ms each side.</translation>
    </message>
</context>
</TS>
